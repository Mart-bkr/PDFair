{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDFix Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import html\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "from random import randrange\n",
    "from urllib.request import urlretrieve\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.tokenize import sent_tokenize\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load WOO dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "woo_dossier_path = \"../woo_dossiers.csv\"\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "woo = pd.read_csv(woo_dossier_path)\n",
    "\n",
    "print(\"Dataframed loaded...\")\n",
    "beslis = woo[woo[\"dc_type\"] == '2e-b']\n",
    "\n",
    "beslis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Save)/ Open row numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of 25 random rownumbers \n",
    "rows = []\n",
    "for x in range(25):\n",
    "    row = randrange(len(beslis))\n",
    "    while row in rows:\n",
    "        row = randrange(len(beslis))\n",
    "    rows.append(row)\n",
    "\n",
    "# Save to file\n",
    "with open('rows.csv', 'w') as file:\n",
    "    write = csv.writer(file)\n",
    "\n",
    "    write.writerow(rows)\n",
    "    \n",
    "# Open rows\n",
    "file = open(\"rows.csv\", \"r\")\n",
    "rows = [int(x) for x in list(csv.reader(file, delimiter=\",\"))[0]]\n",
    "file.close()\n",
    "\n",
    "print(\"len =\", len(rows),\": \", rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add data to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new dataframe\n",
    "df = pd.DataFrame(columns=[\"dc_identifier\", \"dc_title\", \"dc_description\", \"dc_publisher_name\", \"dc_source\", \"foi_publishedDate\"])\n",
    "\n",
    "# Add data from woo_dossiers to dataframe\n",
    "for x in range(len(rows)):\n",
    "    df.loc[x] = beslis.iloc[rows[x]][[\"dc_identifier\", \"dc_title\", \"dc_description\", \"dc_publisher_name\", \"dc_source\", \"foi_publishedDate\"]]\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download files to folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_pdf(woo, row_numbers, row_index, folder_path):  \n",
    "    baseURL = \"https://open.overheid.nl/documenten\"\n",
    "    source = woo.iloc[row_numbers[row_index]]['dc_source']\n",
    "    doi = source[32:-2]\n",
    "    suffixURL = \"/pdf\"\n",
    "    URL = baseURL + doi + suffixURL\n",
    "\n",
    "    print(source)\n",
    "    print(doi)\n",
    "    print(URL)\n",
    "\n",
    "    filename = f\"pdf{row_index}.pdf\"\n",
    "    file_path = folder_path + \"/\" + filename\n",
    "\n",
    "    try:\n",
    "        urlretrieve(URL, file_path)\n",
    "    except:\n",
    "        suffixURL = \"/file\"\n",
    "        URL = baseURL + doi + suffixURL\n",
    "        urlretrieve(URL, file_path)\n",
    "    \n",
    "    print(f\"File downloaded to {file_path}\")\n",
    "    return URL, file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(len(rows)):\n",
    "    download_url, file_path = download_pdf(beslis, rows, x, \"pdfs\")\n",
    "\n",
    "    df.loc[x, \"download_url\"] = download_url\n",
    "    df.loc[x, \"file_path\"] = file_path\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save dataframe to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open dataframe from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"df.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add pdftotext to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(len(rows)):\n",
    "    file_path = f\"pdfs/pdf{x}.pdf\"\n",
    "    txt_path = f\"pdfs/pdf{x}.txt\"\n",
    "    !pdftotext \"$file_path\"\n",
    "    file = open(txt_path)\n",
    "    text = file.read()\n",
    "    file.close()\n",
    "    !rm \"$txt_path\"\n",
    "\n",
    "    df.loc[x, \"pdftotext\"] = text\n",
    "    df.loc[x, \"nCharacters\"] = len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from accessibleHTML import set_metadata, init_analyzer, build_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in tqdm(range(len(rows))):\n",
    "    if x == 0:\n",
    "        continue\n",
    "    file_path = f\"pdfs/pdf{x}.pdf\"\n",
    "    metadata = set_metadata(df.iloc[x], file_path)\n",
    "    document = init_analyzer(file_path)\n",
    "    html = build_html(\n",
    "        doc=document,\n",
    "        metadata=metadata\n",
    "    )\n",
    "    df.loc[x, \"accessible_html\"] = html\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(len(rows)):\n",
    "    html_content = df.loc[x][\"accessible_html\"]\n",
    "\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    html_text = soup.get_text()\n",
    "\n",
    "    df.loc[x, \"html_text\"] = html_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import jaccard_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "for x in range(len(rows)):\n",
    "    corpus = []\n",
    "    corpus.append(df.loc[x][\"pdftotext\"])\n",
    "    corpus.append(df.loc[x][\"html_text\"])\n",
    "\n",
    "    # Tekstgegevens omzetten naar matrix\n",
    "    vectorizer = CountVectorizer()\n",
    "    X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "    # Bereken de cosine similarity tussen de eerste twee zinnen\n",
    "    cosine_sim = cosine_similarity(X[0], X[1])\n",
    "    df.loc[x, \"cosine_sim\"] = cosine_sim[0][0]\n",
    "\n",
    "    # Binaire representaties gebruiken voor Jaccard similarity\n",
    "    X_binary = (X > 0).astype(int)\n",
    "\n",
    "    # Bereken de Jaccard similarity tussen de eerste twee zinnen\n",
    "    jaccard_sim = jaccard_score(X_binary[0].toarray(), X_binary[1].toarray(), average='samples')\n",
    "    df.loc[x, \"jaccard_sim\"] = jaccard_sim\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import jaccard_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "for x in range(len(rows)):\n",
    "    corpus = []\n",
    "    corpus.append(df.loc[x][\"pdftotext\"])\n",
    "    corpus.append(df.loc[x][\"html_text\"])\n",
    "\n",
    "    # Tekstgegevens omzetten naar matrix\n",
    "    vectorizer = CountVectorizer(ngram_range=(1, 3))\n",
    "    X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "    # Bereken de cosine similarity tussen de eerste twee zinnen\n",
    "    cosine_3gram = cosine_similarity(X[0], X[1])\n",
    "    df.loc[x, \"3gram_cosine\"] = cosine_3gram[0][0]\n",
    "\n",
    "    # Binaire representaties gebruiken voor Jaccard similarity\n",
    "    X_binary = (X > 0).astype(int)\n",
    "\n",
    "    # Bereken de Jaccard similarity tussen de eerste twee zinnen\n",
    "    jaccard_3gram = jaccard_score(X_binary[0].toarray(), X_binary[1].toarray(), average='samples')\n",
    "    df.loc[x, \"3gram_jaccard\"] = jaccard_3gram\n",
    "\n",
    "df.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cosine similarity: \" + str(df[\"cosine_sim\"].mean()))\n",
    "print(\"Jaccard similarity: \" + str(df[\"jaccard_sim\"].mean()))\n",
    "print(\"3gram cosine similarity: \" + str(df[\"3gram_cosine\"].mean()))\n",
    "print(\"3gram jaccard similarity: \" + str(df[\"3gram_jaccard\"].mean()))\n",
    "\n",
    "\n",
    "print(\"Cosine similarity STD: \" + str(df[\"cosine_sim\"].std()))\n",
    "print(\"Jaccard similarity STD: \" + str(df[\"jaccard_sim\"].std()))\n",
    "print(\"3gram cosine similarity STD: \" + str(df[\"3gram_cosine\"].std()))\n",
    "print(\"3gram jaccard similarity STD: \" + str(df[\"3gram_jaccard\"].std()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4197b75c41c198a699ac2979e28f5798dac384df611cfc81efbf2b11e344fb2c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
